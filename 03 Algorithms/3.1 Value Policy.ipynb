{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Matrix-Vector form of Value Iteration\n",
    "**Value Policy** 算法是强化学习一个很重要的基础算法，其在每一次迭代过程有两个重要的步骤：\n",
    "- **Plolicy Update(PU)：** 目标是寻找一个策略能够解决如下最优化问题$$\n",
    "\\pi_{k+1} = \\arg \\max (r_{\\pi} + \\gamma P_{\\pi}v_k)$$，其中$v_k$是当前已迭代的状态价值；\n",
    "- **Value Update(VU)：** 计算新的状态价值$v_{k+1}$通过价值迭代公式$$v_{k+1}=r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Elementwise form of Value Iteration\n",
    "#### **Policy Update**\n",
    "在某状态$s$下的时间步$k$，Policy Update(PU) $\n",
    "\\pi_{k+1} = \\arg \\max (r_{\\pi} + \\gamma P_{\\pi}v_k)$的元素形式可以表示为：\n",
    "$$\n",
    "\\pi_{k+1}(s) = \\arg \\max_{\\pi} \\sum_{a \\in \\cal A(s)} \\pi(a|s) \\Big( \\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s') \\Big)\n",
    "$$\n",
    "\n",
    "由之前的介绍可知，上式的的最优解如下：\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\pi_{k+1}(a|s) = 1, & a=a_{k}^*(s) \\\\\n",
    "0, & a\\neq a_{k}^*(s)\n",
    "\\end{cases}\n",
    "$$\n",
    "其中，$a_{k}^*(s)=\\arg \\max_{a \\in \\cal A(s)} q_k (s, a)$, $$\\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s')$$\n",
    "\n",
    "#### Value Update\n",
    "在某状态$s$下的时间步$k$，Value Update $v_{k+1}=r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_k$的元素形式可以表示为：\n",
    "$$\n",
    "v_{k+1}(s) = \\arg \\max_{\\pi} \\sum_{a \\in \\cal A(s)} \\pi(a|s) \\Big( \\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s') \\Big)\n",
    "$$\n",
    "\n",
    "由Policy Update的最优解可知：\n",
    "$$\n",
    "v_{k+1}(s) = \\max_{a \\in \\cal A(s)} q_k (s, a)\n",
    "$$\n",
    "\n",
    "至此，值迭代算法可以被下面的链描述：\n",
    "$$v_k (s) \\rightarrow q_k (s, a) \\rightarrow \\pi_{k+1} (s) \\rightarrow v_{k+1} (s) = \\max_{a \\in \\cal A(s)} q_k (s, a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value Iteration Algorithm：\n",
    "* Value Update：\n",
    "  * 随机初始化$V(s)$\n",
    "  * $while \\ \\delta > \\epsilon$ do:\n",
    "  * $\\qquad$ $\\delta \\leftarrow 0$\n",
    "  * $\\qquad$ for each $s$ in $S$ do:\n",
    "  * $\\qquad\\qquad$ $v \\leftarrow V(s)$\n",
    "  * $\\qquad\\qquad$ $V(s) \\leftarrow \\max_{a} \\{r(s, a) + \\gamma \\sum_{s'} P(s'|s,a) V(s')\\}$\n",
    "  * $\\qquad\\qquad$ $\\delta \\leftarrow \\max(\\delta, |v - V(s)|)$\n",
    "  * end while\n",
    "\n",
    "* Policy Update：\n",
    "  * $\\pi(s) = \\arg\\max_{a} \\{r(s, a) + \\gamma \\sum_{s'} P(s'|s,a) V(s')\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from Utils.gridworld.examples.arguments import args\n",
    "from Utils.gridworld.src.grid_world import GridWorld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    \"\"\" Value Iteration Algorithm \"\"\"\n",
    "\n",
    "    def __init__(self, env, gamma=0.95, delta=0.001):\n",
    "\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.delta = delta\n",
    "\n",
    "        self.state_values = [0] * env.num_states\n",
    "        self.state_policy = [None] * env.num_states\n",
    "\n",
    "    def value_update(self):\n",
    "        \"\"\" Value Update \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def policy_update(self):\n",
    "        \"\"\" Policy Update \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\" Value Iteration Core \"\"\"\n",
    "\n",
    "        steps = 0\n",
    "        while True:\n",
    "            error = 0\n",
    "            values = [0] * self.env.num_states\n",
    "            for state in range(self.env.num_states):\n",
    "                action_values = []\n",
    "                for action in range(self.env.action_space):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
