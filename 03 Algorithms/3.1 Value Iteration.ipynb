{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Matrix-Vector form of Value Iteration\n",
    "根据Bellman Optimal Equation，我们需要解决如下最优方程：\n",
    "$$\n",
    "v = f(v) \\overset{\\cdot}= \\max_{\\pi \\in \\prod}(r_{\\pi} + \\gamma P_{\\pi} v)\n",
    "$$\n",
    "\n",
    "并且我们给出了求解从任意$v_0$开始，进行价值迭代的公式：\n",
    "$$\n",
    "v_{k+1} = f(v_k) = \\max_{\\pi \\in \\prod}(r_{\\pi} + \\gamma P_{\\pi} v_k), \\ \\ \\ k=0,1,2,...\n",
    "$$\n",
    "这一迭代过程，被称为价值迭代（Value Iteration）。\n",
    "**Value Iteration** 算法是强化学习一个很重要的基础算法，其在每一次迭代过程有两个重要的步骤：\n",
    "- **Plolicy Update(PU)：** 目标是寻找一个策略能够解决如下最优化问题$$\n",
    "\\pi_{k+1} = \\arg \\max (r_{\\pi} + \\gamma P_{\\pi}v_k)$$，其中$v_k$是当前已迭代的状态价值；\n",
    "- **Value Update(VU)：** 计算新的状态价值$v_{k+1}$通过价值迭代公式$$v_{k+1}=r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Elementwise form of Value Iteration\n",
    "#### **Policy Update**\n",
    "在某状态$s$下的时间步$k$，Policy Update(PU) $\n",
    "\\pi_{k+1} = \\arg \\max (r_{\\pi} + \\gamma P_{\\pi}v_k)$的元素形式可以表示为：\n",
    "$$\n",
    "\\pi_{k+1}(s) = \\arg \\max_{\\pi} \\sum_{a \\in \\cal A(s)} \\pi(a|s) \\Big( \\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s') \\Big)\n",
    "$$\n",
    "\n",
    "由之前的介绍可知，上式的的最优解如下：\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\pi_{k+1}(a|s) = 1, & a=a_{k}^*(s) \\\\\n",
    "0, & a\\neq a_{k}^*(s)\n",
    "\\end{cases}\n",
    "$$\n",
    "其中，$a_{k}^*(s)=\\arg \\max_{a \\in \\cal A(s)} q_k (s, a)$, $$\\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s')$$\n",
    "\n",
    "#### Value Update\n",
    "在某状态$s$下的时间步$k$，Value Update $v_{k+1}=r_{\\pi_{k+1}} + \\gamma P_{\\pi_{k+1}} v_k$的元素形式可以表示为：\n",
    "$$\n",
    "v_{k+1}(s) = \\arg \\max_{\\pi} \\sum_{a \\in \\cal A(s)} \\pi(a|s) \\Big( \\sum_{r \\in R(s, a)} p(r|s, a)r + \\gamma \\sum_{s' \\in S} p(s'|s, a) v_{k} (s') \\Big)\n",
    "$$\n",
    "\n",
    "由Policy Update的最优解可知：\n",
    "$$\n",
    "v_{k+1}(s) = \\max_{a \\in \\cal A(s)} q_k (s, a)\n",
    "$$\n",
    "\n",
    "至此，值迭代算法可以被下面的链描述：\n",
    "$$v_k (s) \\rightarrow q_k (s, a) \\rightarrow \\pi_{k+1} (s) \\rightarrow v_{k+1} (s) = \\max_{a \\in \\cal A(s)} q_k (s, a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration Algorithm：\n",
    "* 对于所有状态动作对$(s, a)$环境模型的$p(r|s, a)$和$p(s'|s, a)$都已知，随机初始化$v(s)$\n",
    "* $while \\ \\delta > \\epsilon$ do:\n",
    "* $\\qquad$ $\\delta \\leftarrow 0$\n",
    "* $\\qquad$ $for \\ each \\ s \\ in \\ S \\ do$:\n",
    "* $\\qquad\\qquad$ $for \\ each \\ a \\ in \\ \\cal A(s) \\ do$:\n",
    "* $\\qquad\\qquad\\qquad$ $q_k(s, a) \\leftarrow \\sum_r p(r|s,a)r + \\gamma \\sum_{s'} p(s'|s, a)v(s')$\n",
    "* $\\qquad\\qquad$ $end \\ for$\n",
    "* $\\qquad\\qquad$ $a_k^*(s) \\leftarrow \\arg\\max_a q_k(s, a)$\n",
    "* $\\qquad\\qquad$ Policy Update: $\\pi_{k+1}(a|s) = 1$ if $a_k^*(s)=a$, else $0$\n",
    "* $\\qquad\\qquad$ Value Update: $v_{k+1}(s) \\leftarrow \\max_a q_k(s, a)$\n",
    "* $\\qquad$ $end \\ for$\n",
    "* $\\qquad$ $\\delta \\leftarrow \\max(\\delta, |v_k(s) - v_{k+1}(s)|)$\n",
    "* $end \\ while$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Utils.gridworld.examples.arguments import args\n",
    "from Utils.gridworld.src.grid_world import GridWorld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    \"\"\" Value Iteration Algorithm for Grid World \"\"\"\n",
    "\n",
    "    def __init__(self, env, gamma=0.95, delta=1e-3):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.delta = delta\n",
    "\n",
    "        self.values = np.zeros(env.num_states)  # Value function initialization\n",
    "        self.policy = np.zeros((env.num_states, len(env.action_space)))  # Policy initialization\n",
    "\n",
    "\n",
    "    def policy_update(self, q_values):\n",
    "        \"\"\" Update the policy using Greedy \"\"\"\n",
    "\n",
    "        policy = [0] * len(self.env.action_space)\n",
    "        best_action_idx = np.argmax(q_values)  # Get the index of the best action (greedy policy)\n",
    "\n",
    "        policy[best_action_idx] = 1.0  # Set the best action probability to 1.0\n",
    "\n",
    "        return np.array(policy)  # Return the updated\n",
    "\n",
    "    def value_update(self, q_values):\n",
    "        \"\"\" Update the values using Greedy \"\"\"\n",
    "\n",
    "        return max(q_values)\n",
    "\n",
    "    def __get_position(self, state_number):\n",
    "        \"\"\" Get position from state \"\"\"\n",
    "\n",
    "        x = state_number % self.env.env_size[0]\n",
    "        y = state_number // self.env.env_size[0]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __get_state_number(self, state):\n",
    "        \"\"\" Get state number from state tuple \"\"\"\n",
    "\n",
    "        return state[0] * self.env.env_size[0] + state[1]\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            delta = 0\n",
    "            values = np.zeros(self.env.num_states)\n",
    "            for state_number, action_probabilities in enumerate(self.policy):\n",
    "                q_values = []\n",
    "                state = self.__get_position(state_number)\n",
    "                for action in self.env.action_space:\n",
    "                    next_state, reward = self.env.get_next_state_and_reward(state, action)\n",
    "                    next_state_number = self.__get_state_number(next_state)\n",
    "                    q_values.append(self.values[next_state_number] * self.gamma + reward)\n",
    "\n",
    "                self.policy[state_number] = self.policy_update(q_values)  # Update the policy using greedy method\n",
    "                values[state_number] = self.value_update(q_values)  # Update the value using greedy method\n",
    "\n",
    "                delta = max(delta, abs(self.values[state_number] - values[state_number]))  # Update delta\n",
    "            self.values = values\n",
    "            if delta < self.delta: break  # Check for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GridWorld()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: [27.98117299 32.20120928 32.20120928 42.10120928 32.20120928 27.98117299\n",
      " 36.89117299 42.10120928 42.10120928 42.10120928 36.89117299 36.89117299\n",
      " 47.89117299 42.10120928 42.10120928 36.89117299 47.89117299 47.89117299\n",
      " 47.89117299 42.10120928 36.89117299 36.89117299 47.89117299 36.89117299\n",
      " 36.89117299]\n",
      "Policy: [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "agent = ValueIteration(env, gamma=0.9, delta=1e-3)\n",
    "agent.run()\n",
    "print(\"Values:\", agent.values)\n",
    "print(\"Policy:\", agent.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()\n",
    "env.add_policy(agent.policy)\n",
    "env.add_state_values(agent.values)\n",
    "env.render(animation_interval=2)\n",
    "time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
