{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Preliminary Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机过程(Stochastic Process)\n",
    "随机过程是指一系列随机变量的集合，这些随机变量的取值随时间而变化，并且这些随机变量的概率分布随时间而变化。令随机变量在时间 $t$ 时刻的取值为 $S_t$，则称 $S_t$ 为 $t$ 时刻的随机变量，所有随机变量的集合称为随机过程，记为 $\\cal S$;在随机过程的某个时刻 $t$，随机变量/随机状态 $S_t$ 通常取决于$t$时刻之前的状态，即$P(S_{t+1}|S_1, S_2, \\cdots, S_t)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 马尔可夫性质(Markov Property)\n",
    "当且仅当一个随机过程某时刻$t$的状态 $S_t$ 只依赖于 $t-1$ 时刻之前的状态时，这个随机过程被称为具有马尔可夫性质，用公式表示为：\n",
    "$$\n",
    "    P(S_{t+1}|S_t) = P(S_{t+1}|S_1, S_2, \\cdots, S_t)\n",
    "$$\n",
    "\n",
    "**值得注意的是：一个随机过程具有马尔可夫性质并不代表这个随机过程就和历史完全没有关系。** 因为虽然$t+1$时刻的状态只依赖于$t$时刻之前的状态，但$t$时刻的状态可能依赖于$t-1$时刻之前的状态，以此类推，历史信息通过这种链式的关系被传递到当前时刻。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 马尔可夫过程(Markov Process)\n",
    "具有马尔可夫性质的随机过程被称为马尔可夫过程，也被称为马尔可夫链（Markov Chain）。令$\\cal S$表示有限数量的状态集合，令$\\cal P$表示状态转移矩阵，则马尔可夫过程可以用$(\\cal S, \\cal P)$来描述。其中：\n",
    "  $$\n",
    "      \\cal S = \\{s_1, s_2, \\cdots, s_n\\}\n",
    "  $$\n",
    "  $$\n",
    "      \\cal P = \\begin{bmatrix}\n",
    "          P_{11} & P_{12} & \\cdots & P_{1n} \\\\\n",
    "          P_{21} & P_{22} & \\cdots & P_{2n} \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "          P_{n1} & P_{n2} & \\cdots & P_{nn}\n",
    "      \\end{bmatrix}\n",
    "  $$\n",
    "  其中，$P_{ij}$表示从状态$s_i$转移到状态$s_j$的概率，即$P(s_j|s_i)=P(S_{t+1}=s_j|S_t=s_i)$。\n",
    "  另外，从某个状态出发，到达其他状态的概率和必须为1，即：\n",
    "  $\n",
    "      \\sum_{j=1}^n P_{ij} = 1\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个马尔可夫过程的例子\n",
    "<center>\n",
    "<img src=\"../Images/markov-process.png\" alt=\"Markov Process\">\n",
    "</center>\n",
    "\n",
    "状态集合/空间：\n",
    "$$\n",
    "\\cal S = (S_1, S_2, S_3, S_4, S_5, S_6)\n",
    "$$\n",
    "状态转移矩阵：\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.9 & 0.1 & 0 & 0 & 0 & 0 \\\\\n",
    "0.5 & 0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0.6 & 0 & 0.4 \\\\\n",
    "0 & 0 & 0 & 0 & 0.3 & 0.7 \\\\\n",
    "0 & 0.2 & 0.3 & 0.5 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**终止状态：** 不再转移到其他状态，即没有更多的动作可以选择(如示例中的状态$S_6$)。  \n",
    "**状态采样：** 从某个状态出发，根据状态转移矩阵生成一个状态序列$\\text{（Episode）}$的过程被称作状态采样$\\text{(Sampling)}$。如状态采样（从$s_1$出发）：可以生成$s_1 \\rightarrow s_2 \\rightarrow s_3 \\rightarrow s_6$或$s_1 \\rightarrow s_1 \\rightarrow s_2 \\rightarrow s_3 \\rightarrow s_4 \\rightarrow s_6$等状态序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 马尔可夫奖励过程(Markov Reward Process)\n",
    "在马尔可夫过程基础上加入奖励函数$r$和折旧因子$\\gamma$，即马尔可夫奖励过程（Markov Reward Process，MRP），用$(\\cal S, \\cal P, r, \\gamma)$来表示，其中$\\cal S$为状态空间，$\\cal P$为状态转移概率矩阵，$r$为转移某个状态$s$时可以获得奖励的期望——记为$r(s)$——与状态有关，$\\gamma$为折旧因子——取值范围$[0,1)$, 用于衡量未来收益的衰减程度。\n",
    "\n",
    "**回报：** 从$t$时刻状态$S_t$开始，直到终止状态时，所有奖励的衰减值和称为回报，记为$G_t$，即：\n",
    "\n",
    "$$\n",
    "G_t = R_t + \\gamma R_{t+1} + \\gamma^2 R_{t+2} + \\cdots =  \\sum_{k=0}^{\\infty}\\gamma^k r(S_{t+k+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个马尔可夫奖励过程的例子\n",
    "<center>\n",
    "<img src=\"../Images/markov-reward-process.png\" alt=\"Markov Reward Process\">\n",
    "</center>\n",
    "\n",
    "设$\\gamma = 0.5$，状态采样得到一条状态序列为$s_1 \\rightarrow s_2 \\rightarrow s_3 \\rightarrow s_6$，就可以计算$s_1$的回报$G_1$，得到：\n",
    "\n",
    "$$\n",
    "G_1 = r_1 + \\gamma r_2 + \\gamma^2 r_3 + \\gamma^3 r_6 = -1 + 0.5 * (-2) + 0.5^2 * (-2) + 0.5^3 * 0 = -2.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 马尔可夫决策过程(Markov Decision Process)\n",
    "在马尔可夫奖励过程基础上引入智能体的动作，使得智能体能够在有限的时间内做出最优决策，通常使用$\\langle \\cal S,\\cal A,\\cal P,r,\\gamma\\rangle$来表示马尔可夫决策过程。\n",
    "\n",
    "- $\\cal S$是状态空间\n",
    "- $\\cal A$是动作空间\n",
    "- $\\cal P(s'|s,a)$是状态转移函数，表示在状态$s$执行动作$a$后到达状态$s'$的概率\n",
    "- $r(s,a)$是奖励函数，奖励取同时取决于状态$s$和动作$a$\n",
    "- $\\gamma$是折旧因子\n",
    "\n",
    "**简言之，马尔可夫决策过程是一种引入智能体动作的马尔可夫奖励过程（在奖励函数和转移函数上加入了智能体的动作），马尔可夫奖励过程是一种引入奖励函数和折旧因子的马尔可夫过程，马尔可夫过程是一种具备马尔可夫性质的随机过程。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个马尔可夫决策过程的例子\n",
    "<center>\n",
    "<img src=\"../Images/markov-decision-process.png\" alt=\"Markov Decision Process\">\n",
    "</center>\n",
    "\n",
    "在这个例子中有五个状态，分别为$S_1, S_2, S_3, S_4, S_5$；例子中有七个动作，分别为保持$S_1$、前往$S_1$、前往$S_2$、前往$S_3$、前往$S_4$、前往$S_5$、概率前往。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 马尔可夫决策过程转化为马尔可夫奖励过程\n",
    "\n",
    "使用**边缘化**的方法将MDP转化为MRP。对于某一个状态，对所有动作的概率进行加权求和，得到一个关于奖励的边缘分布，就可以认为是一个MRP在该状态下的奖励，即：\n",
    "\n",
    "$$r'(s) = \\sum_{a \\in A} \\pi(a|s) r(s,a)$$\n",
    "同理，计算采取动作的概率使状态$s$转移到$s'$的概率的乘积后求和，得到一个关于转移的边缘分布，就可以认为是一个MRP在状态$s$到$s'$的转移分布，即：\n",
    "\n",
    "$$P'(s'|s) = \\sum_{a \\in A} \\pi(a|s) P(s'|s,a)$$\n",
    "\n",
    "这样，MDP就可以转化为MRP: $\\langle \\cal S,\\cal P',r',\\gamma\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状态空间\n",
    "S = ['s1', 's2', 's3', 's4', 's5']\n",
    "\n",
    "# 动作空间\n",
    "A = ['保持s1', '前往s1', '前往s2','前往s3', '前往s4','前往s5', '概率前往']\n",
    "\n",
    "# 状态转移函数\n",
    "P = {\n",
    "    's1->保持s1-s1': 1.,\n",
    "    's1->前往s2-s2': 1.,\n",
    "    's2->前往s1-s1': 1.,\n",
    "    's2->前往s3-s3': 1.,\n",
    "    's3->前往s4-s4': 1.,\n",
    "    's3->前往s5-s5': 1.,\n",
    "    's4->保持s5-s5': 1.,\n",
    "    's4->概率前往-s2': 0.2,\n",
    "    's4->概率前往-s3': 0.4,\n",
    "    's4->概率前往-s4': 0.4\n",
    "}\n",
    "\n",
    "# 奖励函数\n",
    "R = {\n",
    "    's1->保持s1': -1,\n",
    "    's1->前往s2': 0,\n",
    "    's2->前往s1': -1,\n",
    "    's2->前往s3': -2,\n",
    "    's3->前往s4': -2,\n",
    "    's3->前往s5': 0,\n",
    "    's4->保持s5': 10,\n",
    "    's4->概率前往': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义马尔可夫决策过程\n",
    "gamma = 0.5\n",
    "\n",
    "MDP = (S, A, P, R, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 策略\n",
    "Pi = {\n",
    "    's1->保持s1': 0.5,\n",
    "    's1->前往s2': 0.5,\n",
    "    's2->前往s1': 0.5,\n",
    "    's2->前往s3': 0.5,\n",
    "    's3->前往s4': 0.5,\n",
    "    's3->前往s5': 0.5,\n",
    "    's4->保持s5': 0.5,\n",
    "    's4->概率前往': 0.5\n",
    "}\n",
    "\n",
    "# 转换后的状态转移矩阵: Pi & P -> P'\n",
    "mdp2mrp_p = np.array([\n",
    "    [0.5, 0.5, 0, 0, 0],\n",
    "    [0.5, 0, 0.5, 0, 0],\n",
    "    [0, 0, 0, 0.5, 0.5],\n",
    "    [0, 0.1, 0.2, 0.2, 0.5],\n",
    "    [0, 0, 0, 0, 1.0]\n",
    "])\n",
    "\n",
    "# 转换后的奖励矩阵: Pi & R -> R'\n",
    "mdp2mrp_r = [-0.5, -1.5, -1.0, 5.5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Monte Carlo Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 蒙特卡洛方法\n",
    "一种基于随机采样的方法，它的核心思想是通过大量随机实验来近似求解问题的解，尤其适用于那些难以通过解析方法或确定性算法解决的问题（原理：大数定律），也被称为统计模拟方法，是一种基于概率统计的数值计算方法。\n",
    "\n",
    "**核心特点：**\n",
    "- 随机性：依赖于随机采样，通过生成大量随机样本进行模拟；\n",
    "- 统计性：利用统计学原理对结果进行分析，估计目标值及其误差；\n",
    "- 近似性：通过大量实验逼近真实值，结果的精度岁样本数量的增加而提高；\n",
    "\n",
    "**基本步骤：**\n",
    "- 1.定义问题：将问题转化为概率模型，明确需要计算的量（如期望值、积分、概率等）\n",
    "- 2.生成随机样本：根据问题的概率分布，生成大量随机样本；\n",
    "- 3.计算样本值：对每个样本进行计算，得到目标量的估计值；\n",
    "- 4.统计分析：对结果进行统计分析，计算估计值及其误差（如方差、置信区间等）。\n",
    "\n",
    "**优点：**\n",
    "- 适应性广：可以处理高维、非线性、非解析的问题；适用于复杂的概率分布和随机过程；\n",
    "- 易于实现：算法简单直观、编程实现相对容易；\n",
    "- 并行性强：随机试验相互独立，适合并行计算，提高效率；\n",
    "\n",
    "**缺点：**\n",
    "- 误差通常以$1/\\sqrt{N}$的速度减小；要达到高精度，需要大量的样本；\n",
    "- 结果具有随机性：由于以来随机采样，结果可能存在波动，需要多次试验以确保稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个蒙特卡罗方法的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过蒙特卡洛方法估计圆周率$\\pi$：\n",
    "\n",
    "- 1.定义问题：将圆周率估计问题转化成估计单位圆面积与单位正方形面积比例；\n",
    "- 2.生成随机样本：在单位正方形$[0,1] \\times [0,1]$内随机撒点；\n",
    "- 3.统计分析：统计落在单位元内的点的比例；\n",
    "- 4.问题求解：圆的面积公式，估计$\\pi$值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(N):\n",
    "    \"\"\" Estimate Pi by Monte Carlo: pi / 4 = M / N \"\"\"\n",
    "\n",
    "    M = 0\n",
    "    for _ in range(N):\n",
    "        x = random.uniform(0, 1)\n",
    "        y = random.uniform(0, 1)\n",
    "\n",
    "        if x ** 2 + y ** 2 <= 1:\n",
    "            M += 1\n",
    "\n",
    "    return 4 * M / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1396"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = estimate_pi(100000)\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Dsscent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降(Gradient Descent)\"\"\"\n",
    "梯度下降是一种广发应用于机器学习和优化问题的数值优化算法，用于最小化或最大化目标函数。它通过迭代地调整参数，使得每次调整后的参数都能使目标函数的值减小（或增大）。\n",
    "\n",
    "**梯度下降算法一般流程：**\n",
    "1. 初始化：初始化模型参数的初值 $\\theta_0$；\n",
    "2. 计算梯度：在当前参数下，计算目标函数对参数的梯度 $\\nabla_{\\theta}J(\\theta)$；\n",
    "3. 更新参数：按照负梯度的方向调整参数，即 $\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla_{\\theta}J(\\theta)$，其中 $\\eta$ 是学习率（步长）；\n",
    "4. 重复步骤2和3，直到达到某个停止条件，如达到最大迭代次数或梯度变化小于某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_gradient\n",
    "def compute_gradient(theta, x, y):\n",
    "    \"\"\" Compute the gradient for linear regression. \"\"\"\n",
    "\n",
    "    gradients = 2 / y.shape[0] * (x.T @ (x @ theta - y))\n",
    "    return gradients.ravel()\n",
    "\n",
    "# gradient_descent\n",
    "def gradient_descent(x, y, learning_rate=0.01, num_iters=1000):\n",
    "    \"\"\" Gradient descent algorithm \"\"\"\n",
    "\n",
    "    # Initialize theta parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    for _ in range(num_iters):\n",
    "        gradients = compute_gradient(theta, x, y)\n",
    "        theta -= learning_rate * gradients\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [2.60102170e-04 4.99834982e-01 5.00095084e-01]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = gradient_descent(X, y)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量梯度下降（Batch Gradient Descent）\n",
    "是梯度下降的一个变种，每次迭代使用所有训练数据来计算梯度。特点是每次更新参数时都需要遍历整个数据集，因此优化方向准确、稳定性高、易于实现，但收敛速度较慢、计算量大、内存占用大，需要小一点的学习率，但是最终结果较为准确。\n",
    "\n",
    "**批量梯度下降算法一般流程：**\n",
    "1. 初始化：初始化参数向量 $\\theta$;\n",
    "2. 计算梯度：遍历整个训练集，计算损失函数 $J(\\theta)$ 对 $\\theta$ 的梯度：$g(\\theta^{(t)}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\theta^{(t)})$;\n",
    "3. 更新参数：使用学习率 $\\eta$ 更新参数向量 $\\theta$，即 $\\theta = \\theta - \\eta \\cdot g(\\theta^{(t)})$;\n",
    "4. 重复步骤2和3，直到达到预定的迭代次数或损失函数 $J(\\theta)$ 收敛到某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch gradient descent\n",
    "def batch_gradient_descent(x, y, learning_rate=0.01, num_iters=1000):\n",
    "    \"\"\" Batch Gradient Descent algorithm \"\"\"\n",
    "\n",
    "    # Initialize parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        gradients = compute_gradient(theta, x, y)\n",
    "\n",
    "        theta -= learning_rate * gradients\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [2.60102170e-04 4.99834982e-01 5.00095084e-01]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = batch_gradient_descent(X, y)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机梯度下降（Stochastic Gradient Descent）\"\"\"\n",
    "随机梯度下降（SGD）是一种优化算法，用于最小化一个函数。它通过迭代地调整模型参数来逐步减少损失函数的值。与批量梯度下降不同，SGD在每次迭代中只使用一个样本或一个小批量的样本来计算梯度。这使得SGD比批量梯度下降更快、能够有效避免陷入局部最优解，特别是在数据集非常大的情况下。但由于其随机性，可能会导致收敛过程更加不稳定，并且对学习率的选择比较敏感，同时由于随机选择样本或批量样本，导致梯度估计存在一定的噪声。\n",
    "\n",
    "**随机梯度下降一般流程：**\n",
    "1. 初始化：初始化参数向量 $\\theta$;\n",
    "2. 随机选择样本或小批量样本：从训练集中随机选择一个样本或一个小批量的样本；\n",
    "3. 计算梯度：使用选定的样本损失函数 $J(\\theta)$ 对 $\\theta$ 的梯度：$g(\\theta^{(t)}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\theta^{(t)})$，其中 $m$ 是样本数量;\n",
    "4. 更新参数：使用学习率 $\\eta$ 更新参数向量 $\\theta$，即 $\\theta = \\theta - \\eta \\cdot g(\\theta^{(t)})$;\n",
    "5. 重复步骤2-4，直到达到预定的迭代次数或损失函数 $J(\\theta)$ 收敛到某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "def stochastic_gradient_descent(x, y, batch_size=2, learning_rate=0.01, num_iters=1000):\n",
    "    \"\"\" Stochastic Gradient Descent algorithm \"\"\"\n",
    "\n",
    "    # Initialize parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    for _ in range(num_iters):\n",
    "        # Shuffle the data\n",
    "        indices = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "        x_shuffled = x[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        # Mini-batch gradient descent\n",
    "        gradients = compute_gradient(theta, x_shuffled, y_shuffled)\n",
    "        # Update parameters\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [2.65340447e-04 4.99816035e-01 5.00081375e-01]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = stochastic_gradient_descent(X, y, learning_rate=0.01, num_iters=1000)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动量梯度下降（Momententum Gradient Descent）\n",
    "动量梯度下降是一种优化算法，用于加速训练过程。它通过引入一个动量项来减少震荡并加快收敛速度。\n",
    "\n",
    "**动量梯度下降一般流程：**\n",
    "1. 初始化：设置学习率 $\\eta$ 和动量系数 $\\beta$（通常在0到1之间），以及初始参数 $\\theta$；\n",
    "2. 随机选择样本或小批量样本：从训练集中随机选择一个样本或一个小批量的样本；\n",
    "3. 计算梯度：使用选定的样本损失函数 $J(\\theta)$ 对 $\\theta$ 的梯度：$g(\\theta^{(t)}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\theta^{(t)})$，其中 $m$ 是样本数量;\n",
    "4. 更新速度：使用动量公式更新速度 $v_{t+1} = \\beta v_{t} - \\eta g(\\theta^{(t)})$，其中 $v_0 = 0$;\n",
    "5. 更新参数：使用学习率 $\\eta$ 更新参数向量 $\\theta$，即 $\\theta_{t+1} = \\theta_{t} + v_t$，其中 $v_0 = 0$;\n",
    "6. 重复步骤2-5，直到达到预定的迭代次数或损失函数 $J(\\theta)$ 收敛到某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momententum Gradient Descent\n",
    "def momentum_gradient_descent(x, y, learning_rate=0.1, batch_size=None, momentum=0.9, num_iters=1000):\n",
    "    \"\"\" Momentum Gradient Descent Algorithm \"\"\"\n",
    "\n",
    "    # Initialize velocity\n",
    "    v = np.zeros(x.shape[1])\n",
    "    # Initialize parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    for _ in range(num_iters):\n",
    "        if batch_size is None:\n",
    "            indices = np.arange(x.shape[0])\n",
    "        else:\n",
    "            indices = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "        x_shuffled = x[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        # Compute gradients\n",
    "        gradients = compute_gradient(theta, x_shuffled, y_shuffled)\n",
    "        # Update velocity\n",
    "        v = momentum * v - learning_rate * gradients\n",
    "        # Update parameters\n",
    "        theta += v  # notice the difference here\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [-4.88015023e-16  5.00000000e-01  5.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = momentum_gradient_descent(X, y, learning_rate=0.01, num_iters=1000)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov 加速梯度下降 (Nesterov Accelerated Gradient, NAG)\n",
    "Nesterov 加速梯度下降是一种改进的动量梯度下降算法，它结合了动量和当前梯度的信息。NAG 的核心思想是使用未来的梯度来更新参数，而不是当前的梯度。这使得 NAG 在某些情况下比标准动量方法表现得更好。\n",
    "\n",
    "**Nesterov Accelerated Gradient (NAG) 算法一般流程：**\n",
    "1. 初始化：初始化学习率 $\\eta$、动量系数 $\\beta$ 和参数向量 $\\theta_0$；\n",
    "2. 随机选择样本或小批量样本：从训练集中随机选择一个样本或一个小批量的样本；\n",
    "3. 更新未来位置：使用动量更新参数$\\tilde{\\theta} = \\theta_t + \\beta \\cdot v_t$;\n",
    "4. 计算损失函数关于未来位置的梯度：使用选定的样本损失函数 $J(\\theta)$ 对 $\\tilde{\\theta}$ 的梯度：$g(\\tilde{\\theta}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\tilde{\\theta})$，其中 $m$ 是样本数量;\n",
    "5. 更新速度：$v_{t+1} = \\beta \\cdot v_t + \\eta \\cdot g(\\tilde{\\theta})$;\n",
    "6. 更新参数：$\\theta_{t+1} = \\theta_{t} - v_{t+1}$;\n",
    "7. 重复步骤2-6，直到达到预定的迭代次数或损失函数 $J(\\theta)$ 收敛到某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov Accelerated Gradient (NAG)\n",
    "def nesterov_accelerated_gradient(x, y, batch_size=2, learning_rate=0.1, momentum=0.9, num_iters=1000):\n",
    "    \"\"\" Nesterov Accelerated Gradient (NAG) 优化算法实现 \"\"\"\n",
    "\n",
    "    # initialize parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    # initialize velocity\n",
    "    v = np.zeros_like(theta)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        if batch_size is None:\n",
    "            indices = np.arange(x.shape[0])\n",
    "        else:\n",
    "            indices = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "        x_shuffled = x[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        # update theta\n",
    "        theta_lookahead = theta + momentum * v\n",
    "        # Compute gradients\n",
    "        gradients = compute_gradient(theta_lookahead, x_shuffled, y_shuffled)\n",
    "        # Update velocity\n",
    "        v = momentum * v - learning_rate * gradients\n",
    "        # Update parameters\n",
    "        theta += v  # notice the difference here\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [-5.49789393e-16  5.00000000e-01  5.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = nesterov_accelerated_gradient(X, y, learning_rate=0.01, num_iters=1000)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自适应梯度下降（AdaGrad）\n",
    "AdaGrad是一种自适应学习率的优化算法，它根据参数的历史梯度平方和来调整每个参数的学习率。这样可以确保在不同维度上使用不同的学习率，从而加速收敛并避免震荡。\n",
    "\n",
    "**自适应梯度下降一般流程：**\n",
    "1. 初始化：初始化学习率 $\\eta$、累积梯度向量和$\\mathbf{G}_0$和参数向量 $\\theta_0$；\n",
    "2. 随机选择样本或小批量样本：从训练集中随机选择一个样本或一个小批量的样本；\n",
    "3. 计算梯度：使用选定的样本损失函数 $J(\\theta)$ 对 $\\theta$ 的梯度：$g(\\theta_{t}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\theta_{t})$，其中 $m$ 是样本数量;\n",
    "4. 更新学习率：计算新的学习率 $ \\eta_t = \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} $，其中 $\\mathbf{G}_t$ 是累积梯度向量, $\\epsilon$ 是一个小的常数以避免除零错误；\n",
    "5. 更新参数：$\\theta_{t+1} = \\theta_t - \\eta_t \\cdot g(\\theta_{t})$；\n",
    "6. 更新累积梯度：$\\mathbf{G}_{t+1} = \\mathbf{G}_t + g(\\theta_{t})^2$；\n",
    "7. 重复步骤2-6，直到达到预定的迭代次数或损失函数 $J(\\theta)$ 收敛到某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaGrad\n",
    "def adagrad(x, y, batch_size=2, learning_rate=0.1, num_iters=1000, epsion=1e-6):\n",
    "    \"\"\" AdaGrad \"\"\"\n",
    "    # initialize parameters\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    # initialize gradients\n",
    "    G = 0.0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        if batch_size is None:\n",
    "            indices = np.arange(x.shape[0])\n",
    "        else:\n",
    "            indices = np.random.choice(x.shape[0], batch_size, replace=False)\n",
    "\n",
    "        x_shuffled = x[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        # compute gradients\n",
    "        gradients = compute_gradient(theta, x_shuffled, y_shuffled)\n",
    "        # update G\n",
    "        G += gradients ** 2\n",
    "        # update learning rate\n",
    "        lr = learning_rate / np.sqrt(G + epsion)\n",
    "        # update parameters\n",
    "        theta -= lr * gradients\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [0.04178891 0.54178889 0.45821111]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1.5, 3.5, 5.5, 7.5])\n",
    "\n",
    "# Compute the theta parameters using gradient descent\n",
    "X = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "theta = adagrad(X, y, batch_size=1, learning_rate=0.5, num_iters=1000)\n",
    "print(\"Theta:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadelta\n",
    "Adadelta是一种自适应学习率优化算法，它是对Adagrad算法的扩展，旨在减少其学习率单调递减的问题。在Adagrad算法中，学习率会随着时间逐渐减小，这可能导致学习过程过早停止。Adadelta通过限制累积历史梯度的大小来解决这个问题。**Adadelta算法的主要思想** 是使用一个窗口来累积过去梯度的平方，而不是从开始到现在的所有梯度。这样，学习率就不会随着时间无限减小。具体来说，Adadelta使用了一个参数ρ（通常设置为一个接近1的值，如0.9）来控制窗口的大小。\n",
    "\n",
    "**Adadelta一般流程：**\n",
    "1. 初始化：初始化参数$\\theta_0$，累积平方梯度的指数加权平均$s=0$，累积更新量的指数加权平均$r=0$。\n",
    "2. 随机选择样本或小批量样本：从训练集中随机选择一个样本或一个小批量的样本；\n",
    "3. 计算梯度：使用选定的样本损失函数 $J(\\theta)$ 对 $\\theta$ 的梯度：$g(\\theta_{t}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta J(x_i, y_i; \\theta_{t})$，其中 $m$ 是样本数量;\n",
    "4. 更新累积平方梯度的指数加权平均：$s_{t+1} = \\beta s_{t} + (1 - \\beta) g(\\theta_{t})^{2}$；\n",
    "5. 计算参数更新量：$r_{t+1} = \\frac{\\sqrt{s_{t} + \\epsilon}}{\\sqrt{r_{t}} + \\epsilon} g(\\theta_{t})$；\n",
    "6. 更新模型参数：$\\theta_{t+1} = \\theta_{t} - r_{t+1}$；\n",
    "7. 重复步骤2-6直到达到预定的停止条件（例如，达到最大迭代次数或损失函数 $J(\\theta)$ 的值小于某个阈值）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
